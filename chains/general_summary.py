# -*- coding: utf-8 -*-
"""llamaindex_try.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IoVDUoxTidbCipIro3IFa-N6RrYYijPD
"""

# !pip install -q langchain langchain_groq

from langchain_groq import ChatGroq
from langchain_core.prompts import PromptTemplate
from langchain_core.prompts import ChatPromptTemplate

# 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

llm = ChatGroq(model="llama-3.3-70b-versatile", api_key="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")


system_prompt =  """You are a knowledgeable educational assistant.

When given a study topic, you must return:

1. A very detailed and brief summary on that

2. Key points of the topic
"""

def general_summary(topic_name):
    if topic_name is None:
        return "provide a topic name"
    prompt_template = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("user", "{topic}")
    ])

    messages = prompt_template.format_messages(topic=topic_name)
    response = llm(messages).content.strip()
    return response




